{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e01ae77",
   "metadata": {},
   "source": [
    "# Практикум по линейным моделям в машинном обучении\n",
    "\n",
    "## Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4bd6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Устанавливаем сид для воспроизводимости результатов\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f963889",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Блок 1: Основы линейной регрессии\n",
    "\n",
    "### Задание 1.1: Понимание простейшей линейной модели y = wx + b\n",
    "\n",
    "**Теория:**\n",
    "Линейная регрессия - это простая модель, которая пытается найти прямую линию, наилучшим образом описывающую зависимость между входной переменной x и выходной переменной y.\n",
    "\n",
    "Простейшая модель имеет вид: **y = w*x + b**\n",
    "\n",
    "где:\n",
    "- **w** - вес (наклон прямой)\n",
    "- **b** - смещение (точка пересечения с осью y)\n",
    "- **x** - входной признак\n",
    "- **y** - целевая переменная\n",
    "\n",
    "**Задание:**\n",
    "1. Создайте простые данные и изучите, как меняется линия при разных весах\n",
    "2. Постройте несколько линий с разными параметрами\n",
    "3. Поймите геометрический смысл весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2d68112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# 1. Создайте x от 0 до 10 с шагом 0.5\n",
    "\n",
    "# 2. Постройте 4 разные линии с параметрами:\n",
    "# y1 = 2*x + 1 (w=2, b=1)\n",
    "# y2 = -1*x + 5 (w=-1, b=5)  \n",
    "# y3 = 0.5*x + 2 (w=0.5, b=2)\n",
    "# y4 = 3*x - 2 (w=3, b=-2)\n",
    "\n",
    "# 3. Постройте все линии на одном графике\n",
    "# Подпишите каждую линию: f\"y = {w}x + {b}\"\n",
    "# Добавьте legend, xlabel, ylabel, title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b508b",
   "metadata": {},
   "source": [
    "### Задание 1.2: Создание данных с шумом и визуализация\n",
    "\n",
    "**Теория:**\n",
    "В реальных данных всегда есть шум - случайные отклонения от идеальной зависимости. Наша задача - найти линию, которая лучше всего описывает общую тенденцию.\n",
    "\n",
    "**Задание:**\n",
    "1. Создайте данные по формуле y = 3*x + 2 + шум\n",
    "2. Визуализируйте исходные данные и истинную зависимость\n",
    "3. Добавьте разное количество шума и посмотрите на результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47f87ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# 1. Создайте x от 0 до 10, 50 точек\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2. Создайте \"истинную\" зависимость: y_true = 3*x + 2\n",
    "\n",
    "# 3. Добавьте шум: y_noisy = y_true + np.random.normal(0, 1, len(x))\n",
    "\n",
    "# 4. Постройте график:\n",
    "# - scatter plot зашумленных данных\n",
    "# - линию истинной зависимости (красная линия)\n",
    "# - добавьте легенду и подписи осей\n",
    "\n",
    "# 5. Создайте еще 2 датасета с разным уровнем шума (std=0.5 и std=2)\n",
    "# Постройте их в subplot(1, 3) для сравнения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc87ff",
   "metadata": {},
   "source": [
    "### Задание 1.3: Ручной подбор весов\n",
    "\n",
    "**Теория:**\n",
    "Прежде чем использовать автоматические алгоритмы, попробуем подобрать веса вручную, чтобы понять, как работает процесс обучения.\n",
    "\n",
    "**Задание:**\n",
    "1. Попробуйте разные значения весов и смещений\n",
    "2. Вычислите ошибку для каждого варианта\n",
    "3. Найдите наилучшие параметры визуально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "143519d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# Используйте данные из предыдущего задания (x, y_noisy)\n",
    "\n",
    "# 1. Попробуйте разные веса и смещения:\n",
    "weights_to_try = [1, 2, 3, 4, 5]\n",
    "biases_to_try = [0, 1, 2, 3, 4]\n",
    "\n",
    "# 2. Для каждой комбинации:\n",
    "# - вычислите предсказания: y_pred = w*x + b  \n",
    "# - вычислите MSE c numpy \n",
    "# - сохраните результат\n",
    "\n",
    "# 3. Найдите комбинацию с минимальной ошибкой\n",
    "\n",
    "# 4. Постройте график:\n",
    "# - исходные данные (scatter)\n",
    "# - лучшую найденную линию\n",
    "# - истинную линию для сравнения\n",
    "# Выведите MSE лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d78ae",
   "metadata": {},
   "source": [
    "### Задание 1.4: Введение в sklearn и автоматическое обучение\n",
    "\n",
    "**Теория:**\n",
    "Sklearn автоматически находит оптимальные веса, минимизируя функцию потерь (обычно MSE - среднеквадратичную ошибку).\n",
    "\n",
    "**Задание:**\n",
    "1. Используйте LinearRegression для автоматического поиска весов\n",
    "2. Сравните с вашим ручным подбором\n",
    "3. Изучите найденные коэффициенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0f2dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# 1. Подготовьте данные: x должен быть двумерным массивом\n",
    "X = x.reshape(-1, 1)  # превращаем в столбец\n",
    "y = y_noisy\n",
    "\n",
    "# 2. Создайте и обучите модель\n",
    "# обучите модель\n",
    "\n",
    "# 3. Получите коэффициенты (поля класса coef_ и intercept_):\n",
    "\n",
    "# 4. Сделайте предсказания и вычислите MSE (методы модели fit() и функция mean_squared_error())\n",
    "\n",
    "# 5. Постройте график сравнения:\n",
    "# - исходные данные\n",
    "# - линия sklearn\n",
    "# - ваша лучшая ручная линия  \n",
    "# - истинная линия\n",
    "\n",
    "# 6. Выведите найденные параметры и сравните их с истинными (w=3, b=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff28a9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Блок 2: Работа с многомерными данными\n",
    "\n",
    "### Задание 2.1: Модель с несколькими признаками\n",
    "\n",
    "**Теория:**\n",
    "В реальности у нас обычно больше одного признака. Модель становится:\n",
    "**y = w₁*x₁ + w₂*x₂ + w₃*x₃ + ... + b**\n",
    "\n",
    "Каждый признак имеет свой вес, который показывает, насколько сильно этот признак влияет на результат.\n",
    "\n",
    "**Задание:**\n",
    "1. Создайте данные с 3 признаками\n",
    "2. Изучите влияние каждого признака отдельно\n",
    "3. Обучите модель и проанализируйте веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7523f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# 1. Создайте синтетические данные:\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Массивы признаков с np.random.uniform с границами (0, 10), (1, 5) и (0, 1)\n",
    "\n",
    "# Целевая переменная (например, зарплата)\n",
    "# y = 2*возраст + 5*опыт + 10*образование + 20 + шум\n",
    "\n",
    "# 2. Создайте X матрицу признаков\n",
    "\n",
    "# 3. Постройте 3 графика зависимости y от каждого признака отдельно\n",
    "\n",
    "# 4. Обучите LinearRegression и выведите веса\n",
    "# Сравните найденные веса с истинными [2, 5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5b2bc",
   "metadata": {},
   "source": [
    "### Задание 2.2: Влияние масштаба признаков\n",
    "\n",
    "**Теория:**\n",
    "Если признаки имеют очень разные масштабы, это может повлиять на веса модели. Например, возраст (20-60) и зарплата (20000-100000) имеют разные порядки.\n",
    "\n",
    "**Задание:**\n",
    "1. Создайте данные с признаками разного масштаба\n",
    "2. Обучите модель без масштабирования\n",
    "3. Примените StandardScaler и сравните результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3329daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# 1. Создайте данные с разными масштабами 20, 60 ; 20000, 100000 ; 0, 40:\n",
    "np.random.seed(42)\n",
    "\n",
    "# Целевая переменная (например, стоимость страховки)\n",
    "#y = 0.1*age + 0.0001*income + 2*experience + 100 + шум\n",
    "\n",
    "# 2. Обучите модель БЕЗ масштабирования\n",
    "# обучите и получите коэффициенты\n",
    "\n",
    "# 3. Примените StandardScaler, используйте fit_transform\n",
    "scaler = StandardScaler()\n",
    "# обучите на масштабированных данных\n",
    "\n",
    "# 4. Сравните коэффициенты и MSE\n",
    "# Постройте bar plot коэффициентов до и после масштабирования\n",
    "\n",
    "# 5. Объясните, почему коэффициенты изменились"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006f3bb",
   "metadata": {},
   "source": [
    "### Задание 2.3: Интерпретация весов модели\n",
    "\n",
    "**Теория:**\n",
    "Веса модели показывают, как изменится целевая переменная при изменении признака на единицу (при условии, что остальные признаки не изменяются).\n",
    "\n",
    "**Задание:**\n",
    "1. Обучите модель на осмысленных данных\n",
    "2. Проинтерпретируйте каждый вес\n",
    "3. Найдите самые важные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a64c15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Создаём реалистичные данные о недвижимости\n",
    "np.random.seed(42)\n",
    "n_houses = 200\n",
    "\n",
    "area = np.random.uniform(50, 200, n_houses)        # кв.м\n",
    "rooms = np.random.randint(1, 6, n_houses)           # количество\n",
    "floor = np.random.randint(1, 20, n_houses)             # этаж\n",
    "distance_center = np.random.uniform(1, 50, n_houses) # км от центра\n",
    "\n",
    "# Цена квартиры (тыс. руб)\n",
    "price = (area * 100 +           # 100 тыс за кв.м\n",
    "        rooms * 500 +           # 500 тыс за комнату  \n",
    "        floor * 10 +                # 10 тыс за этаж\n",
    "        distance_center * (-20) +    # -20 тыс за км от центра\n",
    "        5000 +                     # базовая цена\n",
    "        np.random.normal(0, 500, n_houses))  # шум\n",
    "\n",
    "# 2. Обучаем модель\n",
    "\n",
    "# 3. Строим bar plot весов с подписями признаков\n",
    "# Добавляем значения на столбцы\n",
    "\n",
    "# 4. Выводим интерпретацию каждого веса\n",
    "\n",
    "# 5. Ранжируем признаки по важности (по абсолютному значению весов)\n",
    "# Качество модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb040cc3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Блок 3: Кодирование категориальных признаков\n",
    "\n",
    "### Задание 3.1: Проблема с категориальными данными\n",
    "\n",
    "**Теория:**\n",
    "Линейная регрессия работает только с числами. Если у нас есть категориальные признаки (пол, город, образование), их нужно преобразовать в числа.\n",
    "\n",
    "**НЕ ПРАВИЛЬНО:** просто присвоить числа (Мужчина=1, Женщина=2) - это создает ложный порядок.\n",
    "\n",
    "**ПРАВИЛЬНО:** использовать One-Hot Encoding - создать отдельную колонку для каждой категории.\n",
    "\n",
    "**Задание:**\n",
    "1. Создайте данные с категориальными признаками\n",
    "2. Покажите проблему с обычным кодированием\n",
    "3. Сравните с правильным подходом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a520119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# 1. Создайте данные о сотрудниках:\n",
    "np.random.seed(42)\n",
    "n_people = 150\n",
    "\n",
    "age = np.random.uniform(25, 55, n_people)\n",
    "experience = np.random.uniform(0, 30, n_people)\n",
    "\n",
    "# Категориальные признаки\n",
    "gender = np.random.choice(['Мужчина', 'Женщина'], n_people)\n",
    "education = np.random.choice(['Среднее', 'Высшее', 'Магистр'], n_people)\n",
    "\n",
    "# Зарплата зависит от всех факторов\n",
    "base_salary = (age * 1000 + experience * 2000 + 30000)\n",
    "\n",
    "# Добавляем влияние пола и образования\n",
    "gender_bonus = np.where(gender == 'Мужчина', 5000, 0)  # условный пример\n",
    "\n",
    "education_bonus = np.select([\n",
    "    education == 'Среднее',\n",
    "    education == 'Высшее', \n",
    "    education == 'Магистр'\n",
    "], [0, 10000, 20000])\n",
    "\n",
    "salary = base_salary + gender_bonus + education_bonus + np.random.normal(0, 3000, n_people)\n",
    "\n",
    "# 2. Попробуйте НЕПРАВИЛЬНЫЙ способ - LabelEncoder\n",
    "le_пол = LabelEncoder()\n",
    "# Обучите модель с неправильным кодированием\n",
    "\n",
    "# 3. Выведите веса и объясните, почему они могут быть неправильными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d995cb",
   "metadata": {},
   "source": [
    "### Задание 3.2: One-Hot Encoding - правильный способ\n",
    "\n",
    "**Теория:**\n",
    "One-Hot Encoding создает отдельную бинарную колонку для каждой категории:\n",
    "\n",
    "Пол: Мужчина → [1, 0], Женщина → [0, 1]\n",
    "Образование: Среднее → [1, 0, 0], Высшее → [0, 1, 0], Магистр → [0, 0, 1]\n",
    "\n",
    "**Задание:**\n",
    "1. Примените One-Hot Encoding к тем же данным\n",
    "2. Сравните результаты с предыдущим подходом\n",
    "3. Проинтерпретируйте новые веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "502c7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "# Используйте данные из предыдущего задания\n",
    "\n",
    "# 1. Примените OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Для пола\n",
    "ohe_gender = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' избегает мультиколлинеарности\n",
    "gender_onehot = ohe_gender.fit_transform(gender.reshape(-1, 1))\n",
    "\n",
    "# Для образования\n",
    "ohe_education = OneHotEncoder(sparse_output=False, drop='first')\n",
    "education_onehot = ohe_education.fit_transform(education.reshape(-1, 1))\n",
    "\n",
    "# 2. Создайте матрицу признаков\n",
    "\n",
    "# 3. Обучите модель\n",
    "\n",
    "\n",
    "# 4. Создайте названия признаков для интерпретации\n",
    "feature_names = ['Возраст', 'Опыт'] + list(ohe_gender.get_feature_names_out(['Пол'])) + list(ohe_education.get_feature_names_out(['Образование']))\n",
    "\n",
    "# 5. Постройте bar plot весов с подписями\n",
    "# Проинтерпретируйте веса категориальных признаков\n",
    "\n",
    "# 6. Сравните MSE между правильным и неправильным кодированием"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3438b2",
   "metadata": {},
   "source": [
    "### Задание 3.3: Работа с ColumnTransformer\n",
    "\n",
    "**Теория:**\n",
    "ColumnTransformer позволяет применять разные виды предобработки к разным типам признаков одновременно.\n",
    "\n",
    "**Задание:**\n",
    "1. Создайте данные со смешанными типами признаков\n",
    "2. Используйте ColumnTransformer для автоматической обработки\n",
    "3. Создайте полный pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39c9d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [200, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 44\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mСправка по разбиению на тестовую и обучающуюю выборки\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 6. Разделите данные на train/test и обучите pipeline\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 7. Обучите и оцените модель\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Выведите MSE на train и test\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/CheLKSH_2025/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/CheLKSH_2025/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2916\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2914\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2916\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2918\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2919\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2920\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2921\u001b[0m )\n",
      "File \u001b[0;32m~/projects/CheLKSH_2025/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:530\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \n\u001b[1;32m    502\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 530\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/projects/CheLKSH_2025/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:473\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    471\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    476\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [200, 100]"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "# 1. Создайте DataFrame с разными типами данных\n",
    "data = pd.DataFrame({\n",
    "    'возраст': age,\n",
    "    'опыт': experience,\n",
    "    'пол': gender,\n",
    "    'образование': education,\n",
    "    'зарплата': salary\n",
    "})\n",
    "\n",
    "# 2. Разделите на признаки и целевую переменную методами pandas\n",
    "\n",
    "# 3. Определите числовые и категориальные признаки\n",
    "numeric_features = ['age', 'experience']\n",
    "categorical_features = ['gender', 'education']\n",
    "\n",
    "# 4. Создайте ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 5. Создайте Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Справка по разбиению на тестовую и обучающуюю выборки\n",
    "\n",
    "Чтобы протестировать работу модели полезно разбить данные на обучающую и тестовую выборки.\n",
    "Это позволяет оценить, как модель будет работать на новых, не видимых данных.\n",
    "\n",
    "Это можно сделать с помощью функции из sklearn train_test_split(),\n",
    "Она принимает - массив признаков (X) и массив целевой переменной (y), \n",
    "а также параметры test_size и random_state.\n",
    "Выдает - 4 массива: X_train, X_test, y_train, y_test\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 6. Разделите данные на train/test и обучите pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Обучите и оцените модель\n",
    "# Выведите MSE на train и test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
