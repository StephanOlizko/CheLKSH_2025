from pathlib import Path
import nbformat as nbf

def fix_fstring_issues(text):
    """Исправляет проблемы с f-строками в многострочном тексте"""
    # Находим все f-строки с переносами строк
    import re
    
    # Паттерн для поиска проблемных f-строк
    pattern = r'print\(f"([^"]*\n[^"]*?)"\)'
    
    def replace_fstring(match):
        content = match.group(1)
        # Убираем f-префикс если строка содержит только текст без переменных
        if '{' not in content:
            return f'print("{content}")'
        else:
            # Заменяем переносы строк на \\n
            fixed_content = content.replace('\n', '\\n')
            return f'print(f"{fixed_content}")'
    
    # Применяем замену
    fixed_text = re.sub(pattern, replace_fstring, text, flags=re.MULTILINE)
    
    # Дополнительно исправляем случаи где f-строка разбита на несколько строк
    fixed_text = re.sub(r'print\(f"\s*\n\s*([^"]+)"\)', r'print("\1")', fixed_text, flags=re.MULTILINE)
    
    return fixed_text

text_content="""
# Практикум по Pandas
## Занятие для 9-10 классов (120 минут)

# Импорт необходимых библиотек
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Устанавливаем сид для воспроизводимости результатов
np.random.seed(42)
```

# Настройка для корректного отображения графиков и русского текста
```python
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (10, 6)
print("Добро пожаловать на практикум по Pandas!")
print("Сегодня мы изучим основы работы с данными и проведем анализ лагерных активностей")
```

---

## Блок 1: Основы работы с DataFrame (40 минут)

### Задание 1.1: Создание DataFrame из словаря

**Теория:**
DataFrame - это двумерная структура данных в pandas, похожая на таблицу Excel. Можно создавать DataFrame из словарей, списков, CSV файлов.

**Задание:**
1. Создайте DataFrame с данными о 8 участниках лагеря
2. Используйте точно эти имена: Александр, Игорь, Илья, Ярослав, Михаил, Дарья, Мария, Александр
3. Добавьте столбцы с генерацией случайных данных (используйте np.random.seed(42)):
   - возраст: от 15 до 17 лет (случайные целые числа)
   - присядет_за_лагерь: от 500 до 2000 раз (случайные целые числа)
   - опоздает_минут: от 0 до 120 минут (случайные целые числа)
   - жалуется_на_душ: True/False (случайный выбор)
   - заболеет: True/False (случайный выбор)
   - поймают_с_запрещенкой: True/False (случайный выбор)
4. Выведите первые 3 строки с помощью `head(3)`
5. Получите информацию о структуре данных с помощью `info()`

```python
# Ваш код здесь
# ВАЖНО: Установите np.random.seed(42) перед генерацией данных
# 1. Создайте словарь с данными участников лагеря
# 2. Создайте DataFrame с помощью pd.DataFrame()
# 3. Выведите первые 3 строки
# 4. Выведите информацию о DataFrame
```

### Решение 1.1:
```python
# Устанавливаем сид для воспроизводимости
np.random.seed(42)

# Создаем словарь с данными
camp_data = {
    'имя': ['Александр', 'Игорь', 'Илья', 'Ярослав', 'Михаил', 'Дарья', 'Мария', 'Александр'],
    'возраст': np.random.randint(15, 18, 8),
    'присядет_за_лагерь': np.random.randint(500, 2001, 8),
    'опоздает_минут': np.random.randint(0, 121, 8),
    'жалуется_на_душ': np.random.choice([True, False], 8),
    'заболеет': np.random.choice([True, False], 8),
    'поймают_с_запрещенкой': np.random.choice([True, False], 8)
}

# Создаем DataFrame
df_camp = pd.DataFrame(camp_data)
print("DataFrame участников лагеря:")
print(df_camp)

print("\\nПервые 3 строки:")
print(df_camp.head(3))

print("\\nИнформация о DataFrame:")
print(df_camp.info())
```

### Задание 1.2: Создание DataFrame из списков и сохранение в CSV

**Теория:**
DataFrame можно создавать не только из словарей, но и из списков. Pandas позволяет сохранять данные в различных форматах, включая CSV.

**Задание:**
1. Создайте DataFrame из списка списков с данными о комнатах в лагере
2. Используйте данные: [1, 4, True], [2, 3, False], [3, 5, True], [4, 2, False]
3. Назовите столбцы: 'номер_комнаты', 'количество_человек', 'есть_балкон'
4. Сохраните этот DataFrame в файл 'rooms.csv'
5. Загрузите данные обратно и проверьте корректность

```python
# Ваш код здесь
# 1. Создайте DataFrame из списка списков
# 2. Назначьте названия столбцов
# 3. Сохраните в CSV с помощью to_csv()
# 4. Загрузите обратно с помощью pd.read_csv()
```

### Решение 1.2:
```python
# 1. Создаем DataFrame из списка списков
rooms_data = [[1, 4, True], [2, 3, False], [3, 5, True], [4, 2, False]]
df_rooms = pd.DataFrame(rooms_data, columns=['номер_комнаты', 'количество_человек', 'есть_балкон'])

print("DataFrame комнат:")
print(df_rooms)

# 2. Сохраняем в CSV
df_rooms.to_csv('rooms.csv', index=False, encoding='utf-8')
print("\\nДанные сохранены в rooms.csv")

# 3. Загружаем обратно
df_rooms_loaded = pd.read_csv('rooms.csv')
print("\\nДанные загружены из CSV:")
print(df_rooms_loaded)
print("\\nТипы данных после загрузки:")
print(df_rooms_loaded.dtypes)
```

### Задание 1.3: Просмотр структуры данных

**Теория:**
Для анализа данных важно понимать их структуру. Основные методы: `head()`, `tail()`, `info()`, `describe()`, `shape`, `columns`.

**Задание:**
1. Выведите последние 3 строки данных участников лагеря с помощью `tail(3)`
2. Получите описательную статистику для числовых столбцов
3. Выведите названия всех столбцов
4. Узнайте размер DataFrame (количество строк и столбцов)
5. Посмотрите на уникальные значения в столбце 'возраст'

```python
# Ваш код здесь
# 1. Последние 3 строки с помощью tail()
# 2. Описательная статистика с помощью describe()
# 3. Названия столбцов
# 4. Размер DataFrame с помощью shape
# 5. Уникальные значения возраста
```

### Решение 1.3:
```python
# 1. Последние 3 строки
print("Последние 3 строки:")
print(df_camp.tail(3))

# 2. Описательная статистика
print("\\nОписательная статистика:")
print(df_camp.describe())

# 3. Названия столбцов
print("\\nНазвания столбцов:")
print(df_camp.columns.tolist())

# 4. Размер DataFrame
print(f"\\nРазмер DataFrame: {df_camp.shape[0]} строк, {df_camp.shape[1]} столбцов")

# 5. Уникальные значения возраста
print("\\nУникальные значения возраста:")
print(sorted(df_camp['возраст'].unique()))
print(f"Количество уникальных возрастов: {df_camp['возраст'].nunique()}")
```

### Задание 1.4: Индексация и выбор данных (loc, iloc, условная фильтрация)

**Теория:**
Для выбора данных в pandas используются:
- `loc[]` - по названиям строк/столбцов
- `iloc[]` - по числовым индексам
- Условная фильтрация с помощью булевых масок

**Задание:**
1. Выберите данные участника с индексом 2 с помощью `iloc`
2. Выберите столбцы 'имя' и 'возраст' для всех участников с помощью `loc`
3. Найдите всех участников старше 16 лет
4. Найдите участников, которые и заболеют, и будут пойманы с запрещенкой
5. Выберите имена участников, которые присядут больше 1500 раз

```python
# Ваш код здесь
# 1. Данные участника с индексом 2 (iloc)
# 2. Столбцы имя и возраст для всех участников (loc)
# 3. Участники старше 16 лет
# 4. Участники с двумя "проблемами"
# 5. Имена "спортсменов"
```

### Решение 1.4:
```python
# 1. Участник с индексом 2
print("Участник с индексом 2:")
print(df_camp.iloc[2])

# 2. Столбцы имя и возраст
print("\\nИмена и возраст всех участников:")
print(df_camp.loc[:, ['имя', 'возраст']])

# 3. Участники старше 16 лет
older_participants = df_camp[df_camp['возраст'] > 16]
print("\\nУчастники старше 16 лет:")
print(older_participants[['имя', 'возраст']])

# 4. Участники с двумя "проблемами"
problematic = df_camp[(df_camp['заболеет'] == True) & (df_camp['поймают_с_запрещенкой'] == True)]
print("\\nУчастники, которые заболеют И будут пойманы с запрещенкой:")
print(problematic['имя'].tolist())

# 5. "Спортсмены" (много приседаний)
athletes = df_camp[df_camp['присядет_за_лагерь'] > 1500]['имя']
print("\\nУчастники, которые присядут больше 1500 раз:")
print(athletes.tolist())
```

### Задание 1.5: Сортировка данных

**Теория:**
Сортировка данных выполняется с помощью метода `sort_values()`. Можно сортировать по одному или нескольким столбцам, в возрастающем или убывающем порядке.

**Задание:**
1. Отсортируйте участников по возрасту (по возрастанию)
2. Отсортируйте по количеству опозданий (по убыванию)
3. Выполните сортировку сначала по возрасту, затем по количеству приседаний (оба по убыванию)
4. Найдите топ-3 участников по количеству приседаний

```python
# Ваш код здесь
# 1. Сортировка по возрасту
# 2. Сортировка по опозданиям (убывание)
# 3. Двойная сортировка
# 4. Топ-3 по приседаниям
```

### Решение 1.5:
```python
# 1. Сортировка по возрасту
print("Участники, отсортированные по возрасту:")
age_sorted = df_camp.sort_values('возраст')
print(age_sorted[['имя', 'возраст']])

# 2. Сортировка по опозданиям (убывание)
print("\\nУчастники по количеству опозданий (убывание):")
late_sorted = df_camp.sort_values('опоздает_минут', ascending=False)
print(late_sorted[['имя', 'опоздает_минут']])

# 3. Двойная сортировка
print("\\nСортировка по возрасту, затем по приседаниям (убывание):")
double_sorted = df_camp.sort_values(['возраст', 'присядет_за_лагерь'], ascending=[False, False])
print(double_sorted[['имя', 'возраст', 'присядет_за_лагерь']])

# 4. Топ-3 по приседаниям
print("\\nТоп-3 по количеству приседаний:")
top_athletes = df_camp.nlargest(3, 'присядет_за_лагерь')
print(top_athletes[['имя', 'присядет_за_лагерь']])
```

### Задание 1.6: Работа с пропущенными значениями

**Теория:**
В реальных данных часто встречаются пропущенные значения (NaN). Pandas предоставляет инструменты для их обнаружения и обработки.

**Задание:**
1. Создайте копию DataFrame и добавьте несколько пропущенных значений
2. Найдите пропущенные значения с помощью `isnull()`
3. Заполните пропущенные числовые значения средним значением столбца
4. Заполните пропущенные булевы значения значением False
5. Удалите строки с пропущенными значениями в именах (если такие есть)

```python
# Ваш код здесь
# 1. Создайте копию и добавьте NaN значения
# 2. Найдите пропущенные значения
# 3. Заполните числовые пропуски средним
# 4. Заполните булевы пропуски False
# 5. Удалите строки с пропусками в именах
```

### Решение 1.6:
```python
# 1. Создаем копию и добавляем пропущенные значения
df_with_missing = df_camp.copy()
df_with_missing.loc[1, 'возраст'] = np.nan
df_with_missing.loc[3, 'присядет_за_лагерь'] = np.nan
df_with_missing.loc[5, 'заболеет'] = np.nan

print("DataFrame с пропущенными значениями:")
print(df_with_missing)

# 2. Находим пропущенные значения
print("\\nПропущенные значения по столбцам:")
print(df_with_missing.isnull().sum())

# 3. Заполняем числовые пропуски средним значением
df_filled = df_with_missing.copy()
numeric_columns = ['возраст', 'присядет_за_лагерь', 'опоздает_минут']
for col in numeric_columns:
    if df_filled[col].isnull().any():
        mean_value = df_filled[col].mean()
        df_filled[col].fillna(mean_value, inplace=True)
        print(f"\\nЗаполнили пропуски в '{col}' средним значением: {mean_value:.1f}")

# 4. Заполняем булевы пропуски значением False
bool_columns = ['жалуется_на_душ', 'заболеет', 'поймают_с_запрещенкой']
for col in bool_columns:
    if df_filled[col].isnull().any():
        df_filled[col].fillna(False, inplace=True)
        print(f"Заполнили пропуски в '{col}' значением False")

print("\\nDataFrame после заполнения пропусков:")
print(df_filled)
print("\\nПроверка пропущенных значений:")
print(df_filled.isnull().sum())
```

### Задание 1.7: Добавление и удаление столбцов

**Теория:**
В pandas легко добавлять новые столбцы и удалять существующие. Новые столбцы можно создавать на основе вычислений с существующими данными.

**Задание:**
1. Добавьте столбец 'спортивность' (присядет_за_лагерь / 10)
2. Добавьте столбец 'проблемный' (True если заболеет ИЛИ поймают с запрещенкой)
3. Добавьте столбец 'категория_возраста' ('младший' для возраста 15-16, 'старший' для 17+)
4. Удалите столбец 'опоздает_минут'
5. Переименуйте столбец 'жалуется_на_душ' в 'недоволен_условиями'

```python
# Ваш код здесь
# 1. Добавьте столбец спортивность
# 2. Добавьте столбец проблемный
# 3. Добавьте категорию возраста
# 4. Удалите столбец опозданий
# 5. Переименуйте столбец
```

### Решение 1.7:
```python
# Работаем с исходным DataFrame
df_modified = df_camp.copy()

# 1. Добавляем столбец спортивность
df_modified['спортивность'] = df_modified['присядет_за_лагерь'] / 10
print("Добавлен столбец 'спортивность'")

# 2. Добавляем столбец проблемный
df_modified['проблемный'] = (df_modified['заболеет']) | (df_modified['поймают_с_запрещенкой'])
print("Добавлен столбец 'проблемный'")

# 3. Добавляем категорию возраста
df_modified['категория_возраста'] = df_modified['возраст'].apply(
    lambda x: 'младший' if x <= 16 else 'старший'
)
print("Добавлен столбец 'категория_возраста'")

# 4. Удаляем столбец опозданий
df_modified = df_modified.drop('опоздает_минут', axis=1)
print("Удален столбец 'опоздает_минут'")

# 5. Переименовываем столбец
df_modified = df_modified.rename(columns={'жалуется_на_душ': 'недоволен_условиями'})
print("Переименован столбец 'жалуется_на_душ' -> 'недоволен_условиями'")

print("\\nИтоговый DataFrame:")
print(df_modified)
print("\\nСтолбцы в итоговом DataFrame:")
print(df_modified.columns.tolist())
```

### Задание 1.8: Изменение типов данных

**Теория:**
Правильные типы данных важны для эффективной работы и корректных вычислений. Pandas позволяет изменять типы данных с помощью `astype()` и других методов.

**Задание:**
1. Проверьте текущие типы данных в DataFrame
2. Преобразуйте столбец 'возраст' в тип float
3. Преобразуйте булевы столбцы в тип int (True=1, False=0)
4. Создайте столбец 'имя_категория' как категориальный тип данных
5. Проверьте изменения типов и сравните использование памяти

```python
# Ваш код здесь
# 1. Проверьте типы данных
# 2. Преобразуйте возраст в float
# 3. Преобразуйте булевы в int
# 4. Создайте категориальный столбец
# 5. Сравните использование памяти
```

### Решение 1.8:
```python
# 1. Проверяем текущие типы данных
print("Исходные типы данных:")
print(df_camp.dtypes)
print("\\nИспользование памяти:")
print(df_camp.memory_usage(deep=True))

# Создаем копию для преобразований
df_types = df_camp.copy()

# 2. Преобразуем возраст в float
df_types['возраст'] = df_types['возраст'].astype(float)
print("\\nВозраст преобразован в float")

# 3. Преобразуем булевы столбцы в int
bool_columns = ['жалуется_на_душ', 'заболеет', 'поймают_с_запрещенкой']
for col in bool_columns:
    df_types[col] = df_types[col].astype(int)
print("Булевы столбцы преобразованы в int")

# 4. Создаем категориальный столбец
df_types['имя_категория'] = df_types['имя'].astype('category')
print("Создан категориальный столбец")

# 5. Проверяем изменения
print("\\nТипы данных после преобразований:")
print(df_types.dtypes)
print("\\nИспользование памяти после преобразований:")
print(df_types.memory_usage(deep=True))

print("\\nКатегории в столбце 'имя_категория':")
print(df_types['имя_категория'].cat.categories)
print("\\nПример преобразованных данных:")
print(df_types.head())
```

---

## Блок 2: Загрузка и исследование реальных данных (20 минут)

### Задание 2.1: Загрузка и первичный анализ датасета зарплат

**Теория:**
Для загрузки CSV файлов используется `pd.read_csv()`. Для первичного анализа данных полезны методы: `head()`, `tail()`, `info()`, `describe()`, `shape`, `columns`.

**Задание:**
1. Загрузите датасет "Salary Data.csv" в переменную `df`
2. Выведите размер датасета (количество строк и столбцов)
3. Посмотрите на первые 5 строк
4. Получите описательную статистику для числовых столбцов
5. Проверьте наличие пропущенных значений

```python
# Ваш код здесь
# 1. Загрузите CSV файл
# 2. Выведите shape датасета
# 3. Выведите первые 5 строк
# 4. Получите описательную статистику
# 5. Проверьте пропущенные значения с помощью isnull().sum()
```

### Решение 2.1:
```python
# 1. Загружаем датасет
df = pd.read_csv('Salary Data.csv')

# 2. Размер датасета
print(f"Размер датасета: {df.shape[0]} строк, {df.shape[1]} столбцов")

# 3. Первые 5 строк
print("\\nПервые 5 строк:")
print(df.head())

# 4. Описательная статистика
print("\\nОписательная статистика:")
print(df.describe())

# 5. Пропущенные значения
print("\\nПропущенные значения:")
print(df.isnull().sum())

print("\\nНазвания столбцов:")
print(df.columns.tolist())
```

### Задание 2.2: Исследование категориальных данных

**Теория:**
Для анализа категориальных данных используются: `value_counts()`, `unique()`, `nunique()`. Эти методы помогают понять распределение категорий.

**Задание:**
1. Посмотрите уникальные значения в столбце "Gender"
2. Подсчитайте количество людей каждого пола
3. Найдите все уникальные уровни образования
4. Посмотрите топ-5 самых популярных должностей

```python
# Ваш код здесь
# 1. Уникальные значения пола
# 2. Подсчет по полу с помощью value_counts()
# 3. Уникальные уровни образования
# 4. Топ-5 должностей
```

### Решение 2.2:
```python
# 1. Уникальные значения пола
print("Уникальные значения пола:")
print(df['Gender'].unique())

# 2. Распределение по полу
print("\\nРаспределение по полу:")
print(df['Gender'].value_counts())

# 3. Уровни образования
print("\\nУровни образования:")
print(df['Education Level'].unique())
print("\\nРаспределение по образованию:")
print(df['Education Level'].value_counts())

# 4. Топ-5 должностей
print("\\nТоп-5 самых популярных должностей:")
print(df['Job Title'].value_counts().head())
```

---

## Блок 3: Группировка и агрегация данных (25 минут)

### Задание 3.1: Анализ зарплат по группам

**Теория:**
Группировка данных выполняется с помощью `groupby()`. После группировки можно применять агрегирующие функции: `mean()`, `sum()`, `count()`, `min()`, `max()`.

**Задание:**
1. Найдите среднюю зарплату по полу
2. Найдите среднюю зарплату по уровню образования
3. Создайте сводную таблицу средних зарплат по полу и образованию
4. Найдите максимальную и минимальную зарплату для каждого уровня образования

```python
# Ваш код здесь
# 1. Средняя зарплата по полу
# 2. Средняя зарплата по образованию
# 3. Сводная таблица с помощью pivot_table()
# 4. Максимальная и минимальная зарплата по образованию
```

### Решение 3.1:
```python
# 1. Средняя зарплата по полу
salary_by_gender = df.groupby('Gender')['Salary'].mean()
print("Средняя зарплата по полу:")
print(salary_by_gender.round(2))

# 2. Средняя зарплата по образованию
salary_by_education = df.groupby('Education Level')['Salary'].mean().sort_values(ascending=False)
print("\\nСредняя зарплата по уровню образования:")
print(salary_by_education.round(2))

# 3. Сводная таблица
pivot_table = df.pivot_table(values='Salary', 
                            index='Education Level', 
                            columns='Gender', 
                            aggfunc='mean')
print("\\nСводная таблица зарплат (образование × пол):")
print(pivot_table.round(2))

# 4. Мин и макс зарплата по образованию
salary_stats = df.groupby('Education Level')['Salary'].agg(['min', 'max', 'mean'])
print("\\nСтатистика зарплат по образованию:")
print(salary_stats.round(2))
```

### Задание 3.2: Анализ опыта работы и возраста

**Теория:**
Можно группировать данные по нескольким столбцам одновременно и применять различные функции агрегации.

**Задание:**
1. Найдите корреляцию между возрастом и зарплатой
2. Создайте группы по опыту работы (0-5, 6-10, 11-15, 16+ лет)
3. Для каждой группы опыта найдите среднюю зарплату и средний возраст
4. Найдите топ-3 должности с самой высокой средней зарплатой

```python
# Ваш код здесь
# 1. Корреляция возраста и зарплаты
# 2. Создайте столбец с группами опыта с помощью pd.cut()
# 3. Группировка по опыту
# 4. Топ-3 должности по зарплате
```

### Решение 3.2:
```python
# 1. Корреляция возраста и зарплаты
correlation = df['Age'].corr(df['Salary'])
print(f"Корреляция между возрастом и зарплатой: {correlation:.3f}")

# 2. Создаем группы опыта
df['Experience_Group'] = pd.cut(df['Years of Experience'], 
                               bins=[0, 5, 10, 15, float('inf')], 
                               labels=['0-5 лет', '6-10 лет', '11-15 лет', '16+ лет'],
                               include_lowest=True)

# 3. Анализ по группам опыта
exp_analysis = df.groupby('Experience_Group')[['Salary', 'Age']].mean()
print("\\nАнализ по группам опыта:")
print(exp_analysis.round(2))

# 4. Топ-3 должности по зарплате
top_jobs = df.groupby('Job Title')['Salary'].mean().sort_values(ascending=False).head(3)
print("\\nТоп-3 должности по средней зарплате:")
for job, salary in top_jobs.items():
    print(f"{job}: ${salary:,.2f}")
```

---

## Блок 4: Визуализация данных (25 минут)

### Задание 4.1: Базовые графики

**Теория:**
Pandas интегрирован с matplotlib, что позволяет строить графики прямо из DataFrame с помощью метода `.plot()`.

**Задание:**
1. Постройте гистограмму распределения зарплат
2. Создайте box plot зарплат по полу
3. Постройте scatter plot возраста и зарплаты
4. Создайте bar chart средних зарплат по образованию

```python
# Ваш код здесь
# 1. Гистограмма зарплат
# 2. Box plot по полу
# 3. Scatter plot возраст-зарплата
# 4. Bar chart по образованию
```

### Решение 4.1:
```python
# Создаем subplots для размещения графиков
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Гистограмма зарплат
df['Salary'].hist(bins=30, ax=axes[0,0])
axes[0,0].set_title('Распределение зарплат')
axes[0,0].set_xlabel('Зарплата ($)')
axes[0,0].set_ylabel('Частота')

# 2. Box plot по полу
df.boxplot(column='Salary', by='Gender', ax=axes[0,1])
axes[0,1].set_title('Распределение зарплат по полу')
axes[0,1].set_xlabel('Пол')
axes[0,1].set_ylabel('Зарплата ($)')

# 3. Scatter plot возраст-зарплата
df.plot.scatter(x='Age', y='Salary', ax=axes[1,0], alpha=0.6)
axes[1,0].set_title('Зависимость зарплаты от возраста')

# 4. Bar chart по образованию
salary_by_education.plot.bar(ax=axes[1,1])
axes[1,1].set_title('Средняя зарплата по образованию')
axes[1,1].set_xlabel('Уровень образования')
axes[1,1].set_ylabel('Средняя зарплата ($)')
axes[1,1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()
```

### Задание 4.2: Продвинутая визуализация с matplotlib

**Теория:**
Matplotlib предоставляет широкие возможности для создания информативных графиков. Можно создавать тепловые карты, violin plot-подобные графики и другие визуализации.

**Задание:**
1. Создайте тепловую карту корреляций числовых переменных
2. Постройте распределение зарплат по образованию (гистограммы)
3. Создайте многомерный scatter plot с раскраской по полу
4. Постройте горизонтальную диаграмму для анализа распределения должностей (топ-10)

```python
# Ваш код здесь
# 1. Тепловая карта корреляций с помощью imshow
# 2. Гистограммы зарплат по образованию
# 3. Scatter plot с раскраской по полу
# 4. Горизонтальная диаграмма топ-10 должностей
```

### Решение 4.2:
```python
# Подготавливаем данные для визуализации
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# 1. Тепловая карта корреляций
numeric_cols = ['Age', 'Years of Experience', 'Salary']
correlation_matrix = df[numeric_cols].corr()

im = axes[0,0].imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)
axes[0,0].set_xticks(range(len(numeric_cols)))
axes[0,0].set_yticks(range(len(numeric_cols)))
axes[0,0].set_xticklabels(numeric_cols, rotation=45)
axes[0,0].set_yticklabels(numeric_cols)

# Добавляем значения корреляций на карту
for i in range(len(numeric_cols)):
    for j in range(len(numeric_cols)):
        text = axes[0,0].text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',
                             ha="center", va="center", color="black", fontweight='bold')

axes[0,0].set_title('Корреляции числовых переменных')
plt.colorbar(im, ax=axes[0,0])

# 2. Гистограммы зарплат по образованию
education_levels = df['Education Level'].unique()
colors = plt.cm.Set1(np.linspace(0, 1, len(education_levels)))

for i, edu_level in enumerate(education_levels):
    edu_data = df[df['Education Level'] == edu_level]['Salary']
    axes[0,1].hist(edu_data, alpha=0.7, label=edu_level, color=colors[i], bins=20)

axes[0,1].set_xlabel('Зарплата ($)')
axes[0,1].set_ylabel('Частота')
axes[0,1].set_title('Распределение зарплат по образованию')
axes[0,1].legend()

# 3. Scatter plot с раскраской по полу
colors_gender = {'Male': 'blue', 'Female': 'red'}
for gender in df['Gender'].unique():
    gender_data = df[df['Gender'] == gender]
    axes[1,0].scatter(gender_data['Years of Experience'], gender_data['Salary'], 
                     label=gender, alpha=0.6, color=colors_gender.get(gender, 'gray'))
axes[1,0].set_xlabel('Опыт работы (лет)')
axes[1,0].set_ylabel('Зарплата ($)')
axes[1,0].set_title('Зарплата vs Опыт (по полу)')
axes[1,0].legend()

# 4. Горизонтальная диаграмма топ-10 должностей
top_jobs_counts = df['Job Title'].value_counts().head(10)
y_pos = range(len(top_jobs_counts))

axes[1,1].barh(y_pos, top_jobs_counts.values)
axes[1,1].set_yticks(y_pos)
axes[1,1].set_yticklabels(top_jobs_counts.index)
axes[1,1].set_xlabel('Количество сотрудников')
axes[1,1].set_title('Топ-10 должностей по количеству')

plt.tight_layout()
plt.show()
```

---

## Блок 5: Продвинутый анализ данных (20 минут)

### Задание 5.1: Создание новых признаков и анализ

**Теория:**
Часто нужно создавать новые столбцы на основе существующих данных для более глубокого анализа.

**Задание:**
1. Создайте столбец "Salary_per_Experience" (зарплата на год опыта)
2. Создайте категории зарплат: "Low" (<75k), "Medium" (75k-125k), "High" (>125k)
3. Найдите средний возраст для каждой категории зарплат
4. Определите, какой процент людей с PhD получает зарплату в категории "High"

```python
# Ваш код здесь
# 1. Создайте Salary_per_Experience
# 2. Создайте категории зарплат с помощью pd.cut()
# 3. Средний возраст по категориям зарплат
# 4. Процент PhD в категории High
```

### Решение 5.1:
```python
# 1. Зарплата на год опыта (избегаем деления на 0)
df['Salary_per_Experience'] = df['Salary'] / (df['Years of Experience'] + 1)

# 2. Категории зарплат
df['Salary_Category'] = pd.cut(df['Salary'], 
                              bins=[0, 75000, 125000, float('inf')], 
                              labels=['Low', 'Medium', 'High'])

print("Распределение по категориям зарплат:")
print(df['Salary_Category'].value_counts())

# 3. Средний возраст по категориям зарплат
age_by_salary_cat = df.groupby('Salary_Category')['Age'].mean()
print("\\nСредний возраст по категориям зарплат:")
print(age_by_salary_cat.round(1))

# 4. Процент PhD в категории High
phd_high_salary = df[(df['Education Level'] == 'PhD') & (df['Salary_Category'] == 'High')]
total_phd = df[df['Education Level'] == 'PhD']
percentage = len(phd_high_salary) / len(total_phd) * 100

print(f"\\nПроцент людей с PhD в категории High: {percentage:.1f}%")

# Дополнительная статистика
print("\\nТоп-5 по зарплате на год опыта:")
print(df.nlargest(5, 'Salary_per_Experience')[['Job Title', 'Salary', 'Years of Experience', 'Salary_per_Experience']])
```

### Задание 5.2: Итоговый анализ и выводы

**Теория:**
Финальный анализ должен объединить все полученные знания и дать практические выводы.

**Задание:**
1. Найдите самую высокооплачиваемую должность в среднем
2. Определите оптимальный уровень образования с точки зрения ROI (зарплата/годы обучения)
3. Создайте профиль "идеального" кандидата для высокой зарплаты
4. Сделайте 3 практических вывода из анализа данных

```python
# Ваш код здесь
# 1. Самая высокооплачиваемая должность
# 2. ROI по образованию (предположим: Bachelor's=4 года, Master's=6, PhD=8)
# 3. Анализ характеристик людей с зарплатой >150k
# 4. Выводы
```

### Решение 5.2:
```python
# 1. Самая высокооплачиваемая должность
highest_paid_job = df.groupby('Job Title')['Salary'].mean().sort_values(ascending=False)
print("Топ-5 самых высокооплачиваемых должностей:")
print(highest_paid_job.head().round(2))

# 2. ROI по образованию
education_years = {'High School': 0, "Bachelor's": 4, "Master's": 6, 'PhD': 8}
df['Education_Years'] = df['Education Level'].map(education_years)
df['Education_ROI'] = df['Salary'] / (df['Education_Years'] + 1)  # +1 чтобы избежать деления на 0

roi_by_education = df.groupby('Education Level')['Education_ROI'].mean().sort_values(ascending=False)
print("ROI по уровню образования (зарплата/годы обучения):")
print(roi_by_education.round(2))

# 3. Профиль для высокой зарплаты (>150k)
high_earners = df[df['Salary'] > 150000]
print(f"\\nАнализ высокооплачиваемых сотрудников ({len(high_earners)} человек):")
print(f"Средний возраст: {high_earners['Age'].mean():.1f} лет")
print(f"Средний опыт: {high_earners['Years of Experience'].mean():.1f} лет")
print("Распределение по образованию:")
print(high_earners['Education Level'].value_counts(normalize=True).round(3) * 100)
print("Распределение по полу:")
print(high_earners['Gender'].value_counts(normalize=True).round(3) * 100)

# 4. Практические выводы
print("\\n" + "="*50)
print("ПРАКТИЧЕСКИЕ ВЫВОДЫ:")
print("="*50)
print("1. ОБРАЗОВАНИЕ: Магистерская степень дает лучший баланс зарплаты и времени обучения")
print(f"2. ОПЫТ: Сотрудники с зарплатой >150k имеют в среднем {high_earners['Years of Experience'].mean():.1f} лет опыта")
print("3. ДОЛЖНОСТИ: Управленческие позиции (Director, Senior Manager) показывают наивысшие зарплаты")
```

---

## Заключение

**Поздравляем! Вы успешно освоили основы работы с pandas:**

✅ Создание и манипулирование DataFrame  
✅ Загрузка и исследование реальных данных  
✅ Группировка и агрегация данных  
✅ Визуализация результатов  
✅ Создание новых признаков и анализ  

**Дополнительные задачи для самостоятельной работы:**
1. Исследуйте зависимость зарплаты от комбинации возраста и опыта
2. Найдите аномалии в данных (необычно высокие/низкие зарплаты)
3. Создайте модель для предсказания категории зарплаты
4. Проведите анализ по географическим регионам (если добавить столбец с городами)

```python
print("Спасибо за участие в практикуме по pandas!")
print("Теперь вы готовы к более сложным задачам анализа данных!")
```
"""

text_content = fix_fstring_issues(text_content)

import re

nb = nbf.v4.new_notebook()

# Исправленное регулярное выражение для поиска блоков кода
pattern = re.compile(r'```python\n(.*?)\n```', re.DOTALL)

# Находим все блоки кода
code_matches = list(pattern.finditer(text_content))

# Разбиваем текст на части
parts = []
last_end = 0

for match in code_matches:
    # Добавляем текст перед блоком кода
    text_before = text_content[last_end:match.start()]
    if text_before.strip():
        parts.append(('text', text_before.strip()))
    
    # Добавляем блок кода
    code_block = match.group(1)
    if code_block.strip():
        parts.append(('code', code_block.strip()))
    
    last_end = match.end()

# Добавляем оставшийся текст
remaining_text = text_content[last_end:]
if remaining_text.strip():
    parts.append(('text', remaining_text.strip()))

# Создаем ячейки
cells = []
for part_type, content in parts:
    if part_type == 'text':
        cells.append(nbf.v4.new_markdown_cell(content))
    else:  # code
        cells.append(nbf.v4.new_code_cell(content))

nb['cells'] = cells

# Сохраняем ноутбук
output_path = Path("pandas.ipynb")
with open(output_path, "w", encoding="utf-8") as f:
    nbf.write(nb, f)

print(f"Ноутбук успешно создан: {output_path}")
print(f"Создано {len(cells)} ячеек")