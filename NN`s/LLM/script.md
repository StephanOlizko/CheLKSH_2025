# Занятие: Большие языковые модели и искусственный интеллект
**Аудитория:** 7 класс  
**Время:** 90 минут (2 академических часа)  
**Уровень:** Базовые знания ПК, представление о том что такое программирование

---

## 0:00–0:10 — Вступление и мотивация

**Приветствие и знакомство с темой**

Добро пожаловать на занятие о том, как компьютеры научились понимать и говорить на человеческом языке! Сегодня мы разберем, как работают такие программы как ChatGPT, Claude, Яндекс Алиса и другие "умные" помощники, которые могут отвечать на вопросы, писать тексты и даже помогать с домашними заданиями.

**Вопросы для вовлечения аудитории:**
- Кто из вас уже пользовался ChatGPT или другими AI-помощниками?
- Что самое интересное или удивительное вы с их помощью делали?
- Как вы думаете, действительно ли компьютер "понимает" то, что мы ему пишем?

**Анонс занятия:**
Сегодня мы пройдем удивительный путь от простых букв и слов до сложных нейронных сетей, которые умеют разговаривать почти как люди. Мы узнаем, как компьютер превращает наши слова в числа, как он угадывает следующее слово в предложении, и почему иногда AI дает странные или неправильные ответы. А в конце мы сами попробуем "поговорить" с настоящими языковыми моделями и научимся задавать им правильные вопросы.

---

## 0:10–0:25 — Токенизация: как компьютер читает текст

### (0:10–0:17) — От букв к токенам

**Объяснение проблемы:**
Представьте, что вы пытаетесь объяснить инопланетянину, который никогда не видел человеческого языка, что означает фраза "Привет, как дела?". С чего бы вы начали? Компьютеры сталкиваются с похожей проблемой — они умеют работать только с числами, а мы даем им буквы и слова.

**Демонстрация на доске/экране:**
Возьмем простое предложение: "Я учусь программировать"

Первый шаг — разбить текст на отдельные части, которые называются токенами. Токен — это наименьшая единица текста, которую компьютер обрабатывает как одно целое.

```
Исходный текст: "Я учусь программировать"
Токены: ["Я", "уч", "усь", "программ", "ировать"]
```

**Интерактивный момент:**
Давайте вместе попробуем разбить на токены фразу "Машинное обучение". Как вы думаете, на какие части её можно разделить? 

*Принимаем варианты от учеников, обсуждаем разные подходы*

### (0:17–0:25) — Почему токенизация важна

**Объяснение принципов:**
Токенизация — это не просто разрезание текста на кусочки. Хорошая токенизация должна учитывать смысл языка. Например, слово "программирование" лучше разбить на "программ" + "ирование", чем на случайные буквы, потому что части слова несут смысловую нагрузку.

**Практический пример:**
Рассмотрим, как разные подходы к токенизации влияют на понимание:

Плохая токенизация: "п-р-о-г-р-а-м-м-и-р-о-в-а-н-и-е" (по буквам)
Хорошая токенизация: "программ-ирование" (по смысловым частям)

**Связь с реальностью:**
Современные языковые модели, такие как GPT, используют специальный алгоритм токенизации, который анализирует миллионы текстов и автоматически находит наилучший способ разбития слов. Обычно в русском языке одно слово превращается в 1-3 токена.

---

## 0:25–0:45 — Эмбеддинги: превращаем слова в числа

### (0:25–0:33) — Мешок слов: первый шаг к пониманию

**Постановка задачи:**
Теперь у нас есть токены, но компьютер по-прежнему не может с ними работать, потому что не понимает, что такое "программ" или "ирование". Нужно превратить слова в числа таким образом, чтобы сохранить их смысл.

**Простейший подход — мешок слов:**
Представим, что у нас есть словарь из всех слов русского языка, и мы каждому слову присваиваем номер:
- "я" = 1
- "ты" = 2  
- "программа" = 3
- "компьютер" = 4
- ... и так далее

**Демонстрация на примере:**
Фраза "Я изучаю программы" превратится в список чисел: [1, 0, 1, 0, 0] где:
- Позиция 1 (слово "я") = 1 (встречается один раз)
- Позиция 2 (слово "ты") = 0 (не встречается)
- Позиция 3 (слово "программа") = 1 (встречается один раз в форме "программы")
- И так далее

### (0:33–0:45) — Современные эмбеддинги: слова как точки в пространстве

**Проблема простого подхода:**
Мешок слов не учитывает, что слова "программа" и "компьютер" связаны по смыслу, а слова "программа" и "банан" — нет. Как это исправить?

**Концепция векторных представлений:**
Современные модели представляют каждое слово как точку в многомерном пространстве. Представьте трехмерную комнату, где каждое слово — это точка с координатами (x, y, z). Похожие по смыслу слова располагаются рядом друг с другом.

**Визуализация на двумерной плоскости:**
На доске рисуем координатную плоскость и показываем примерное расположение слов:
- "программа", "код", "алгоритм" — кластер в одной области
- "собака", "кошка", "хомяк" — кластер в другой области  
- "яблоко", "груша", "банан" — третий кластер

**Магия векторной арифметики:**
В таком пространстве можно выполнять арифметические операции со словами! Классический пример:
"король" - "мужчина" + "женщина" = "королева"

**Практическое задание:**
Попробуйте предсказать результат: "Москва" - "Россия" + "Франция" = ?
*Обсуждаем ответы учеников, объясняем логику*

---

## 0:45–1:05 — Как работает чат-бот: предсказание следующего слова

### (0:45–0:52) — Основная идея языковых моделей

**Центральная концепция:**
Представьте, что вы играете в игру "Угадай следующее слово". Я говорю: "В магазине я купил молоко и..." — что будет дальше? Скорее всего, "хлеб", "сыр" или что-то съедобное, но точно не "самолет" или "теорему".

Языковые модели работают точно так же — они анализируют текст и предсказывают, какое слово наиболее вероятно появится следующим.

**Демонстрация предсказания:**
Возьмем предложение: "Сегодня на улице идет..."
Возможные варианты и их вероятности:
- "дождь" — 40%
- "снег" — 30% 
- "град" — 15%
- "самолет" — 0.001%

**Интерактивное упражнение:**
Давайте вместе поиграем! Я начну предложение, а вы предложите варианты продолжения:
"На уроке информатики мы изучаем..."
*Собираем варианты от учеников, обсуждаем, какие более вероятны и почему*

### (0:52–1:05) — От одного слова к длинным текстам

**Пошаговая генерация:**
Но как из предсказания одного слова получается целый рассказ или ответ на вопрос? Очень просто — модель делает это пошагово:

Шаг 1: "Программирование — это"
Предсказание: "искусство" (добавляем к тексту)

Шаг 2: "Программирование — это искусство"  
Предсказание: "создания" (добавляем к тексту)

Шаг 3: "Программирование — это искусство создания"
Предсказание: "компьютерных" (добавляем к тексту)

И так далее, пока не получится полный ответ.

**Демонстрация с классом:**
Давайте попробуем сами сгенерировать текст! Я начну: "Искусственный интеллект в будущем будет..."
Каждый ученик по очереди добавляет одно слово, которое кажется ему наиболее логичным продолжением.

**Проблема контекста:**
А что, если текст очень длинный? Представьте, что модель читает целую книгу и должна предсказать следующее слово. Неужели она помнит каждое слово с самого начала? Здесь мы подходим к важной концепции — ограничению контекста.

---

## 1:05–1:20 — Контекст и внимание: как модель помнит важное

### (1:05–1:12) — Проблема длинных текстов

**Ограничения памяти:**
Представьте, что вы читаете книгу на 1000 страниц, а потом вас спрашивают: "О чем говорилось на 27 странице?" Сложно вспомнить все детали, правда? У языковых моделей похожая проблема — они могут "помнить" только определенное количество последних слов.

**Окно контекста:**
Современные модели имеют "окно контекста" — это максимальное количество токенов, которые они могут учитывать одновременно. Например:
- GPT-3.5: около 4000 токенов (примерно 3000 слов)
- GPT-4: до 128000 токенов (примерно 100000 слов)
- Claude: до 200000 токенов

**Практический пример:**
Если вы вставите в чат-бот целую книгу и зададите вопрос о начале, он может не вспомнить детали, потому что они "выпали" из окна контекста.

### (1:12–1:20) — Механизм внимания на пальцах

**Аналогия с классной комнатой:**
Представьте, что учитель задает вопрос: "Какой химический элемент мы изучали на прошлом уроке, когда говорили о том, что он нужен для дыхания?"

Чтобы ответить, вы должны:
1. Обратить внимание на слова "химический элемент"
2. Вспомнить связь с "дыханием"  
3. Связать эти понятия и вспомнить "кислород"

**Как это работает в модели:**
Механизм внимания позволяет модели "сфокусироваться" на важных частях текста при генерации ответа. Когда модель предсказывает следующее слово, она не просто смотрит на предыдущее слово, а анализирует весь контекст и определяет, какие части наиболее важны.

**Визуализация:**
На доске рисуем предложение: "Мой кот, который живет у бабушки в деревне, очень любит..."

При предсказании следующего слова модель обращает внимание на:
- "кот" (высокое внимание — главный субъект)
- "любит" (высокое внимание — ключевое действие)  
- "который живет у бабушки" (низкое внимание — дополнительная информация)

**Интерактивное задание:**
В предложении "Студент, изучающий программирование в университете, написал свою первую..." на какие слова должна обратить внимание модель для предсказания следующего слова?
*Обсуждаем с классом, выделяем ключевые слова*

---

## 1:20–1:35 — Разнобразие и контроль: температура и системные промпты

### (1:20–1:27) — Проблема одинаковых ответов

**Демонстрация проблемы:**
Если модель всегда выбирает самое вероятное следующее слово, то на вопрос "Расскажи анекдот" она будет отвечать одним и тем же анекдотом каждый раз. Скучно, правда?

**Введение случайности — температура:**
Температура в языковых моделях — это параметр, который контролирует "творческость" ответов:

- Температура = 0: модель всегда выбирает самое вероятное слово (предсказуемые, "безопасные" ответы)
- Температура = 1: модель учитывает вероятности, но может выбирать менее вероятные варианты (креативные ответы)
- Температура = 2: очень высокая творческость, но возможны странные или бессмысленные ответы

**Аналогия с приготовлением еды:**
Низкая температура = готовим по строгому рецепту
Высокая температура = импровизируем, добавляем неожиданные ингредиенты

**Практический пример:**
Вопрос: "Как провести выходные?"

Температура 0: "Можно сходить в кино, погулять в парке или почитать книгу"
Температура 1: "Попробуйте заняться фотографией заката или устроить пикник на балконе"
Температура 2: "Постройте замок из подушек и притворитесь, что вы археолог из будущего"

### (1:27–1:35) — Системные промпты: как управлять поведением AI

**Что такое системный промпт:**
Системный промпт — это скрытая инструкция, которая говорит модели, как себя вести. Это как роль в спектакле или правила игры, которые модель должна соблюдать.

**Примеры системных промптов:**
- "Ты — учитель математики, объясняй сложные темы простыми словами"
- "Ты — веселый помощник, который отвечает с юмором"  
- "Ты — строгий редактор, который исправляет ошибки в текстах"

**Демонстрация влияния:**
Вопрос: "Что такое переменная в программировании?"

С промптом "учитель для детей":
"Переменная — это как коробочка с наклейкой, куда можно положить число или слово, а потом достать их, когда понадобится"

С промптом "технический эксперт":
"Переменная — это именованная область памяти, предназначенная для хранения данных определенного типа с возможностью изменения значения в процессе выполнения программы"

**Интерактивное упражнение:**
Придумайте системный промпт для AI-помощника, который помогает с домашними заданиями. Каким он должен быть?
*Собираем идеи от учеников, обсуждаем плюсы и минусы разных подходов*

---

## 1:35–1:50 — Обучение моделей: от текстов к интеллекту

### (1:35–1:42) — Обучение на больших данных

**Масштаб современных моделей:**
Чтобы понять, насколько большие современные языковые модели, представьте:
- GPT-3 обучалась на тексте объемом около 500 миллиардов слов
- Это примерно 1 миллион книг среднего размера
- Если печатать этот текст со скоростью 200 слов в минуту без остановки, потребуется около 4700 лет

**Параметры модели:**
Параметры — это числа внутри модели, которые определяют, как она обрабатывает информацию. Можно представить их как настройки гигантской машины:
- GPT-3: 175 миллиардов параметров
- GPT-4: предположительно более триллиона параметров

**Аналогия с обучением человека:**
Представьте, что ребенок учится говорить, читая все книги в библиотеке, все статьи в интернете, все разговоры людей. Именно так обучаются языковые модели — они анализируют огромные объемы текста и учатся предсказывать, как люди говорят и пишут.

### (1:42–1:50) — Два этапа обучения

**Этап 1: Предобучение (Pre-training):**
На этом этапе модель просто учится предсказывать следующее слово в тексте. Она читает миллиарды предложений и учится понимать закономерности языка: грамматику, факты о мире, стиль речи.

**Этап 2: Обучение с подкреплением от человеческой обратной связи (RLHF):**
После предобучения модель умеет генерировать текст, но не всегда полезный или безопасный. Поэтому люди оценивают ответы модели:
- Какой ответ лучше?
- Этот ответ полезный или вредный?
- Следует ли модель инструкциям?

**Проблема интерпретируемости:**
Самая большая загадка современных языковых моделей — мы не понимаем, как именно они работают внутри. У нас есть миллиарды параметров, но мы не можем сказать: "Этот параметр отвечает за понимание математики, а тот — за юмор".

Это как если бы у нас был мозг, состоящий из триллионов связей, и мы знали бы, что он может думать, но не понимали бы, как именно каждая связь влияет на мысли.

---

## 1:50–2:15 — Практическая работа: знакомство с современными моделями

### (1:50–1:57) — Обзор современных моделей

**Лидеры рынка на 2024 год:**
Давайте познакомимся с самыми мощными языковыми моделями, доступными сегодня:

**OpenAI:**
- ChatGPT (GPT-4) — один из самых известных и качественных AI-помощников
- Отлично справляется с объяснениями, написанием текстов, программированием
- Сайт: chat.openai.com

**Anthropic:**
- Claude — модель, разработанная с упором на безопасность и полезность  
- Хорошо понимает контекст, дает развернутые объяснения
- Сайт: claude.ai

**Google:**
- Gemini (бывший Bard) — модель от создателей поисковика Google
- Интегрирована с сервисами Google, хорошо работает с поиском информации
- Сайт: gemini.google.com

**Российские решения:**
- Яндекс Алиса — голосовой помощник, но также умеет работать с текстом
- GigaChat от Сбера — российская альтернativa ChatGPT

**Локальные модели:**
- Llama от Meta — открытая модель, которую можно запустить на своем компьютере
- Mistral — европейская компания с качественными моделями

### (1:57–2:08) — Параметры API и настройки

**Что такое API:**
API (Application Programming Interface) — это способ для программ общаться с языковой моделью. Представьте, что это телефон, по которому ваша программа может "позвонить" модели и получить ответ.

**Основные параметры запроса:**

**1. Temperature (Температура): 0.0 - 2.0**
- 0.0 = предсказуемые, точные ответы
- 1.0 = баланс между точностью и креативностью  
- 2.0 = очень креативные, но возможно странные ответы

**2. Max tokens (Максимальное количество токенов):**
- Ограничение длины ответа
- 100 токенов ≈ 75 слов русского текста

**3. Top-p (Nucleus sampling): 0.0 - 1.0**
- Альтернатива температуре для контроля разнообразия
- 0.1 = выбор только из самых вероятных слов
- 1.0 = рассмотрение всех возможных вариантов

**Пример API запроса (упрощенно):**
```
Сообщение: "Объясни квантовую физику простыми словами"
Температура: 0.7
Максимум токенов: 200
Системный промпт: "Ты учитель физики для школьников"
```

### (2:08–2:15) — Живая демонстрация

**Практическое задание:**
Сейчас мы попробуем поработать с настоящей языковой моделью. Я покажу, как изменение параметров влияет на ответы.

**Эксперимент 1: Влияние температуры**
Вопрос: "Придумай название для нового мессенджера"

Температура 0.1: [Демонстрируем получение консервативного ответа]
Температура 1.5: [Демонстрируем получение креативного ответа]

**Эксперимент 2: Влияние системного промпта**
Вопрос: "Как решить квадратное уравнение?"

Промпт 1: "Ты строгий учитель математики"
Промпт 2: "Ты веселый мультяшный персонаж, который объясняет математику"

*Показываем разницу в стиле и подаче одной и той же информации*

---

## 2:15–2:25 — Искусство промптинга: как правильно общаться с AI

### Основные принципы эффективного промптинга

**1. Будьте конкретными:**
Плохо: "Помоги с математикой"
Хорошо: "Объясни, как решать систему линейных уравнений методом подстановки, и покажи пример"

**2. Задавайте контекст:**
Плохо: "Переведи текст"
Хорошо: "Переведи этот технический текст о программировании с английского на русский, сохраняя терминологию"

**3. Используйте примеры:**
"Напиши краткое изложение статьи в таком же стиле:
Пример: 'Исследование показало, что регулярная физическая активность улучшает память на 15%'
Теперь сделай так же с этой статьей: [текст статьи]"

**4. Разбивайте сложные задачи:**
Вместо: "Напиши курсовую работу о влиянии интернета на общество"
Лучше: 
- Сначала: "Составь план курсовой работы о влиянии интернета на общество"
- Потом: "Напиши введение по этому плану"
- Затем: "Развей первый пункт плана"

**Интерактивное упражнение:**
Давайте вместе улучшим плохие промпты:
- "Сделай презентацию" → ?
- "Помоги с английским" → ?
- "Что думаешь об этом?" → ?

*Работаем с классом над улучшением промптов*

---

## 2:25–2:30 — Заключение и важные моменты

### Возможности и ограничения AI

**Где AI действительно полезен:**
- Объяснение сложных тем простыми словами
- Генерация идей и творческих решений  
- Помощь в написании и редактировании текстов
- Программирование и отладка кода
- Перевод и работа с языками
- Анализ и структурирование информации

**Важные ограничения:**
- AI может давать неточную или устаревшую информацию
- Не всегда понимает контекст так же, как человек
- Может "галлюцинировать" — выдумывать факты
- Не заменяет критическое мышление и проверку фактов

**Правила безопасного использования AI в учебе:**
1. Всегда проверяйте факты из других источников
2. Используйте AI как помощника, а не как замену собственного мышления
3. Указывайте, если использовали AI при выполнении заданий (если требуется)
4. Развивайте собственные навыки параллельно с использованием AI

**Заключительная мысль:**
Языковые модели — это мощный инструмент, который может стать отличным помощником в учебе и творчестве. Но помните: самый важный "процессор" — это ваш собственный мозг. AI дополняет человеческий интеллект, но не заменяет его.

Удачи в изучении этой увлекательной области технологий!

---

## Материалы для подготовки

**Технические требования:**
- Проектор или интерактивная доска
- Доступ к интернету для демонстрации AI-моделей
- Компьютер преподавателя с браузером

**Дополнительные материалы:**
- Шпаргалка с основными терминами для учеников
- Примеры хороших и плохих промптов
- Ссылки на официальные сайты AI-сервисов

**Домашнее задание (по желанию):**
Попробовайте пообщаться с одной из языковых моделей (ChatGPT, Claude, Gemini) и задайте ей 3 вопроса на разные темы. Оцените качество ответов и подумайте, как можно было бы улучшить свои вопросы для получения более полезных ответов.